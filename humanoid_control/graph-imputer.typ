= Graph Imputer

== Overview

This paper introduces a method for multiagent time-series imputation,
specifically applied to predicting the trajectories of off-screen football
players. The primary goal is to fill in missing player tracking data from
sources like broadcast video, enabling the use of advanced football analytics
that require the positions of all players. The proposed model, the *Graph
Imputer*, outperforms existing methods, including those specifically designed
for football, in both trajectory prediction accuracy and in a downstream pitch
control analysis task.

=== Challenges and Approaches

- *Challenge: Imputing Trajectories of Temporarily Unobserved Agents*
  - In many scenarios, like broadcast football footage, only a subset of agents
    (players) are visible at any given time, while unobserved agents continue to
    interact off-screen. Standard forward-prediction models are ill-suited for
    this "imputation" task because they cannot account for future observations
    when an agent reappears on-screen.
  - *Approach:* The paper proposes a model that uses both past and future
    information to estimate missing trajectories. This is achieved with a
    bidirectional architecture that processes the time series in both forward
    and backward directions and fuses the results.
  - *Hypothesis:* By leveraging both past and future context, the model can
    produce more accurate and physically plausible trajectories that adhere to
    the boundary constraints imposed by when players disappear and reappear from
    view. Furthermore, modeling the explicit interactions between all players is
    critical for accurate predictions.
  - *Alternative Solutions Considered:*
    - *Interpolation:* Simple spline interpolation (linear, quadratic, cubic)
      between the points where a player leaves and re-enters the camera view.
    - *Unidirectional Prediction Models:* Forward-prediction models like Social
      LSTM and Graph Variational RNNs (GVRNNs) that only use past observations
      to forecast future states.

- *Challenge: Enabling Downstream Analytics Under Partial Observability*
  - Many established sports analytics frameworks, such as Pitch Control, rely on
    having the complete tracking data for all players on the pitch. This
    dependency restricts their application to data from proprietary,
    fully-instrumented stadiums, rather than more widely available broadcast
    footage.
  - *Approach:* The imputed trajectories generated by the Graph Imputer are used
    as a complete dataset to run the Pitch Control analysis. The accuracy is
    then measured by comparing the resulting Pitch Control fields to those
    generated from the ground truth data.
  - *Hypothesis:* A more accurate trajectory imputation model will enable a more
    reliable and accurate application of downstream analytics that traditionally
    require fully observed data.

=== The Graph Imputer Model

- The *Graph Imputer* is the novel model proposed for multiagent imputation. It
  is designed to be general and not restricted to the football domain.
- It combines three main components:
  1. *Bidirectional LSTMs:* To process temporal information from both past and
    future observations for each agent.
  2. *Graph Networks (GraphNets):* To model the complex spatial interactions
    between all agents (players and the ball) at each timestep.
  3. *Variational Autoencoder (VAE) Framework:* To learn a distribution over
    possible trajectories, capturing the stochastic nature of human
    decision-making.
- *Inputs:*
  - The partial time-series of agent states, $x$, which contains the observed
    (on-screen) positions of players.
  - An agent-wise masking matrix, $m$, indicating which agents are observed at
    each timestep.
- *Output:*
  - A full prediction, $hat(x)$, containing the estimated trajectories for all
    agents across all timesteps, effectively filling in the missing data.

=== Dependencies

- *Dataset:* The study uses a proprietary dataset of 105 English Premier League
  matches, containing tracking data for all players and the ball at 25
  frames-per-second. This dataset is not publicly available.
- *Existing Frameworks:* The evaluation of the model for downstream tasks relies
  on a pre-existing *Pitch Control* model, which is a well-known technique in
  football analytics for calculating a team's control over the pitch.
- *Baseline Models:* The performance of the Graph Imputer is compared against
  several existing models, including Social LSTM and GVRNNs.

=== Assumptions

- The model requires that each agent is observed for at least one timestep
  within a given trajectory sequence.
- The number of agents (22 players and the ball) is assumed to be constant
  throughout each trajectory clip.
- The simulated camera used to create partial observability is simplified to
  always track the ball's position.

=== Recommended Prerequisite Knowledge

- To fully understand the downstream evaluation, familiarity with the concept of
  *Pitch Control* is beneficial. The paper references the following work for
  details on the pitch control model used:
  - Spearman, W., Basye, A., Dick, G., Hotovy, R. & Pop, P. Physics-based
    modeling of pass probabilities in soccer. In *Proc. 11th MIT Sloan Sports
    Analytics Conference* (2017).

== Problem Formulation

The paper addresses the *multiagent time-series imputation problem*. The
objective is to estimate the missing states (e.g., positions) of multiple
interacting agents given a sequence of observations where any subset of agents
can be unobserved at any given time.

- *System Definition*
  - Let $II=(1,...,N )$ be a set of $N$ agents. In the football context, this
    includes 22 players and the ball, so $N=23$.
  - Let $TT=(0,...,T )$ be a sequence of discrete timesteps.
  - The state of an agent $i in II$ at time $t in TT$ is a $d$-dimensional
    vector $x_t^i in RR^d$. For the football use case, this corresponds to the
    2D position, so $d=2$.
  - The complete ground truth trajectory data for all agents is denoted as
    $x = x_(0:T)^(1:N)$.

- *Partial Observability*
  - A binary masking matrix $m$ of the same dimension as $x$ indicates whether
    an agent's state is observed.
  - $m_t^i$ is a vector where each dimension is 1 if the corresponding dimension
    of the agent's state is observed at time $t$, and 0 otherwise. In the
    football setting, a player is either fully observed or not, so
    $m_t^i in ((0,0), (1,1))$.

- *Objective*
  - The problem takes the observed states, which can be represented by the
    Hadamard (element-wise) product $x dot.circle m$, as input .
  - The goal is to output a full prediction of all agent states for all
    timesteps, $hat(x) = hat(x)_(0:T)^(1:N)$.

- *Evaluation*
  - The performance of the imputation is quantified by calculating the
    $cal(L)_2$ loss between the predicted states and the ground truth states for
    all the timesteps and agents that were *not* observed.

$
  cal(L)_2 (hat(x) dot.circle(1 - m), x dot.circle(1 - m))
$

== Pipeline

The model operates by running two parallel passes over the data—one forward in
time and one backward—and then fusing their predictions. The following pipeline
details the process for a single directional pass (forward), which is then
repeated for the backward direction.

=== Input Combination

This stage prepares the input for the LSTM at each timestep by merging ground
truth data with the model's own previous predictions.

- *Inputs:*
  - Ground truth state at time $t$: $x_t$, with shape $(N, d)$.
  - Mask at time $t$: $m_t$, with shape $(N, d)$.
  - Autoregressively-predicted state from the previous step: $hat(arrow(x))_t$,
    with shape $(N, d)$. This is the output from Stage 4 in the previous
    timestep, $t-1$.
- *Description:*
  - For each agent, if its state is observed (indicated by the mask $m_t$), the
    ground truth state $x_t$ is used. If the state is missing, the model's own
    prediction from the previous step, $hat(arrow(x))_t$, is used instead.
  - This is calculated using *Equation (1)*:

$
  arrow(tilde(x))_t = x_t dot.circle m_t + hat(arrow(x))_t dot.circle (1-m_t)
$

- *Output:*
  - Combined input state for the current timestep: $arrow(tilde(x))_t$, with
    shape $(N, d)$.

=== Temporal Integration (LSTM)

This stage updates the temporal context for each agent using a recurrent neural
network.

- *Inputs:*
  - Combined input state for each agent: $arrow(tilde(x))_t^i$, with shape
    $(d)$.
  - Previous LSTM hidden state for each agent: $arrow(h)_(t-1)^i$, with shape
    $"hidden_dim"$. The paper uses a hidden dimension of 64.
- *Description:*
  - The combined input from Stage 1 is fed into a 2-layer LSTM to update its
    hidden state, capturing the temporal dynamics of each agent's trajectory.
    The LSTM parameters are shared across all agents.
  - This update follows *Equation (2)* :

$
  arrow(h)_t^i = "LSTM"_arrow(omega) (arrow(tilde(x))_t^i, arrow(h)_(t - 1)^i)
$

- *Output:*
  - Updated LSTM hidden states for all agents: $arrow(h)_t$, with shape
    $(N, "hidden_dim")$.

=== Variational Update (Graph Networks)

This stage models the interactions between agents and generates a stochastic
latent variable to represent the game state.

- *Inputs:*
  - The collection of previous LSTM hidden states for all agents:
    $arrow(h)_(t-1)$, with shape $(N, "hidden_dim")$.
  - (During training only) Ground truth state at time $t$: $x_t$, with shape
    $(N, d)$.
- *Description:*
  - The LSTM hidden states $arrow(h)_(t-1)$ are used as initial node features in
    a fully-connected graph where each node represents an agent.
  - A *GraphNet Prior* takes $arrow(h)_(t-1)$ to parameterize a Gaussian prior
    distribution $p_theta(arrow(z)_t | dot)$ over a latent variable $z_t$ for
    each agent. This is used during evaluation.
  - At training time, a *GraphNet Encoder* takes both $arrow(h)_(t-1)$ and the
    true state $x_t$ to parameterize a Gaussian posterior distribution
    $q_phi(arrow(z)_t | dot)$.
  - Latent variables are then sampled from the appropriate distribution
    ($arrow(z)_t ~ q_phi$ during training, $arrow(z)_t ~ p_theta$ during
    evaluation).
- *Output:*
  - Sampled latent variables for all agents: $arrow(z)_t$, with shape
    $(N, "latent_dim")$. The paper uses a latent dimension of 16.

=== State Prediction

This stage decodes the latent variables into a predicted change in player
positions.

- *Inputs:*
  - Sampled latent variables: $arrow(z)_t$, with shape $(N, "latent_dim")$.
  - Previous LSTM hidden states: $arrow(h)_(t-1)$, with shape
    $(N, "hidden_dim")$.
- *Description:*
  - A *GraphNet Decoder* takes the latent variables $arrow(z)_t$ and the hidden
    states $arrow(h)_(t-1)$ as input to its nodes.
  - After message passing between nodes, the decoder outputs a predicted
    relative state change for each agent. This step uses *Equation (11)* to
    produce parameters for the output distribution and *Equation (8)* to sample
    the final output .
  - The predicted state change is added to the previous state to get the
    absolute position for the next timestep, using *Equation (12)*:

$
  hat(arrow(x))_t = arrow(tilde(x))_(t - 1) + Delta hat(arrow(x))_t
$

- *Output:*
  - The autoregressively-predicted state for the next step: $hat(arrow(x))_t$,
    with shape $(N, d)$. This output is used as input for Stage 1 in the next
    timestep, $t+1$.

=== Bidirectional Fusion

This final stage combines the predictions from the forward pass and an analogous
backward pass to produce the final imputed trajectory.

- *Inputs:*
  - The full sequence of forward-direction estimates: $hat(arrow(x))$, with
    shape $(T, N, d)$.
  - The full sequence of backward-direction estimates: $hat(arrow.l(x))$, with
    shape $(T, N, d)$.
- *Description:*
  - The backward pass repeats Stages 1-4 but processes the data in reverse time,
    from $T$ down to $0$.
  - At each timestep $t$, the forward prediction $hat(arrow(x))_t$ and backward
    prediction $hat(arrow.l(x))_t$ are fused into a single estimate $hat(x)_t$.
  - Two fusion methods are considered:
    1. *Mean Fusion:* A simple average, using *Equation (13)*.
    2. *Nearest-Weighted Fusion:* A weighted average based on the proximity of
      the nearest future/past ground truth observation, using *Equation (14)*.
- *Output:*
  - The final imputed trajectory: $hat(x)$, with shape $(T, N, d)$.

== Discussion

=== How accurate is the Graph Imputer at the primary task of predicting off-screen player trajectories compared to other methods?

This question assesses the model's core performance on the imputation task
itself.

- *Experiments and Ablations*
  - The primary experiment involved training and evaluating the Graph Imputer
    and a suite of baseline models on the task of off-screen player state
    estimation.
  - *Dataset:* A dataset of 105 English Premier League matches was used, with
    player and ball tracking data partitioned into 9.6-second trajectories.
  - *Task Simulation:* A simulated broadcast camera that tracks the ball was
    used to create partial observability, masking out players who were
    off-screen.
  - *Baselines:* The model was compared against three categories of baselines:
    1. *Simple Interpolation:* Linear, quadratic, and cubic splines.
    2. *General Trajectory Models:* Autoregressive LSTMs, Social LSTMs, and
      GVRNNs, including bidirectional variants implemented by the authors.
    3. *Football-Specific Models:* Role-invariant VRNNs that were hand-crafted
      for the football scenario.
  - *Ablation Studies:* The authors tested variants of their Graph Imputer and
    the GVRNN model to measure the impact of two key architectural features: the
    presence of a *skip connection* and a *next-step conditional decoder*.

- *Metrics Used*
  - *$cal(L)_2$(Mean):* The mean Euclidean distance between the model's
    predicted trajectory and the ground truth for all unobserved portions of the
    trajectory.
  - *$cal(L)_2$(Min.):* For stochastic models, this metric measures the
    $cal(L)_2$ error of the single best trajectory out of 6 generated samples,
    providing an assessment of the model's ability to generate at least one
    highly plausible outcome.

- *Results and Significance*
  - The *Graph Imputer significantly outperformed all baseline models* on both
    the mean and minimum $cal(L)_2$ error metrics. This includes outperforming
    models that were specifically hand-crafted for the football domain,
    highlighting the strength of its general multi-agent architecture.
  - The results strongly confirmed the authors' hypothesis that
    *bidirectionality is crucial* for imputation. Models that used both past and
    future information (e.g., Bidirectional Social LSTM, Graph Imputer)
    consistently and substantially outperformed their unidirectional
    counterparts.
  - The ablation studies showed that including a *skip connection* from the
    input to the decoder provided a significant performance improvement for all
    variational models.

- *Limitations*
  - The experiments relied on a *simulated camera* to generate partial
    observability rather than actual broadcast footage, which might not fully
    capture the complexities of a real-world scenario.
  - The training and testing data were partitioned from the same set of 105
    matches. This setup does not test the model's ability to generalize or
    transfer its learning to different teams, leagues, or stadiums, which would
    be essential for a practical, vision-based application.

=== Can the Graph Imputer's predictions be used to enable complex downstream analytics that traditionally require fully observed data?

This question evaluates the practical, real-world utility of the model beyond
just raw prediction accuracy.

- *Experiments and Ablations*
  - The authors designed an experiment using *Pitch Control*, a well-established
    football analytic that calculates a team's control over every area of the
    pitch and requires the positions of all players.
  - First, ground truth pitch control fields were computed using the fully
    observed validation dataset.
  - Next, player positions were occluded using the simulated camera, and the
    Graph Imputer and other strong baselines were used to generate complete,
    imputed trajectories.
  - Finally, pitch control fields were calculated from these imputed
    trajectories and compared against the ground truth fields.

- *Metrics Used*
  - *Mean Absolute Error (MAE):* The MAE between the pitch control field
    generated from the imputed trajectories and the ground truth field, averaged
    over the entire pitch and the full duration of each trajectory sequence.

- *Results and Significance*
  - The *Graph Imputer yielded the lowest MAE* in the pitch control analysis,
    demonstrating that its imputed trajectories were the most useful for this
    downstream task.
  - Qualitative visualizations showed that competing models like GVRNN produced
    large errors in tactically critical areas, such as near the goalkeepers. The
    Graph Imputer's predictions were more robust, leading to more reliable
    analytical outputs.
  - *This is a key result of the paper*, as it proves the model can successfully
    unlock the use of powerful analytical tools on datasets with only partial
    information (e.g., from broadcast video), which was previously not feasible.

- *Limitations*
  - The analysis was restricted to one specific downstream task (Pitch Control).
    While it's a strong indicator, the performance might vary for other types of
    analytics.

=== What are the inherent limitations of the proposed model architecture and what are the key areas for future research?

This question is addressed in the paper's conclusion, where the authors reflect
on the model's design and propose future improvements.

- *Discussion (No Experiment)*
  - This section is based on a critical analysis of the model's architecture
    rather than a direct experiment. The authors identify several areas for
    potential improvement based on the current design's constraints .

- *Metrics Used*
  - Not applicable, as this is a qualitative discussion of the model's design.

- *Identified Limitations and Future Work*
  - *Independent Latent Sampling:* In the current model, the latent variables
    for the forward- and backward-directional passes are sampled independently.
    The authors suggest that sampling them from a joint distribution could
    improve the correlation and consistency of the directional predictions.
  - *Requirement for an Initial Observation:* The model requires that every
    agent is observed at least once in a trajectory sequence. Future work could
    investigate how to handle agents that are completely unobserved for an
    entire sequence.
  - *Simple Fusion Method:* The bidirectional fusion is done via a simple mean
    or weighted average. An improvement would be to incorporate the model's
    predicted distributional information (e.g., covariance matrices) into the
    fusion process, potentially using ideas from information filtering
    techniques.

